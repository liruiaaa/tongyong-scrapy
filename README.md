# -scrapy
一个通用的scrapy已经配置完基本只需要在spider文件下加文件就可以
存储是异步存入mysql有需要自己更改吧pipeline注释打开就可以
里面配置存到elasticsearch中的方法分局需要自己改
可以运行scrapy crawlall运行全部爬虫把setting注释打开就可以
